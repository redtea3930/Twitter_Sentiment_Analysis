{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "571e8716-f7ec-402c-bab9-db01b33f02c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbe2a63-f0b3-4635-ace7-f7ec805c84fc",
   "metadata": {},
   "source": [
    "## Data importation\n",
    "Technical difficulties prevented me from importing full dataset. Despite encoding of the original csv in UTC-8, \n",
    "Jupyter Lab insisted the original csv. I was able to open the original csv in Excel, export it as a new csv specified to be encoded in UTC-8, and then import that new csv in Jupyter Lab successfully. This limited the dataset to 1M lines, removing some 600,000 rows. This should still be a sizable dataset for analysis, however as the original data was ordered by sentiment, this removed a significant amount of positive sentimented text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7b51bd1-b4da-4362-8257-349c112c4dbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>query</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>4</td>\n",
       "      <td>1879942807</td>\n",
       "      <td>Thu May 21 23:36:19 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>divabat</td>\n",
       "      <td>@healingsinger thank you, i needed that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>4</td>\n",
       "      <td>1879942922</td>\n",
       "      <td>Thu May 21 23:36:20 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>nick1975</td>\n",
       "      <td>@vactress http://bit.ly/cADea  Maybe this is m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>4</td>\n",
       "      <td>1879942975</td>\n",
       "      <td>Thu May 21 23:36:21 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>znmeb</td>\n",
       "      <td>@Brat13 Hell, Windows 7 will be out of my pric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>4</td>\n",
       "      <td>1879943113</td>\n",
       "      <td>Thu May 21 23:36:22 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>virmani</td>\n",
       "      <td>@jigardoshi neah.. i wish! just reminiscing  r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>4</td>\n",
       "      <td>1879943219</td>\n",
       "      <td>Thu May 21 23:36:24 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>redcomet81</td>\n",
       "      <td>@MsTeagan ...and by the way: I rewatched Sun G...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentiment          id                          time     query  \\\n",
       "0               0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1               0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2               0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3               0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4               0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "...           ...         ...                           ...       ...   \n",
       "999995          4  1879942807  Thu May 21 23:36:19 PDT 2009  NO_QUERY   \n",
       "999996          4  1879942922  Thu May 21 23:36:20 PDT 2009  NO_QUERY   \n",
       "999997          4  1879942975  Thu May 21 23:36:21 PDT 2009  NO_QUERY   \n",
       "999998          4  1879943113  Thu May 21 23:36:22 PDT 2009  NO_QUERY   \n",
       "999999          4  1879943219  Thu May 21 23:36:24 PDT 2009  NO_QUERY   \n",
       "\n",
       "                   name                                               text  \n",
       "0       _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1         scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2              mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3               ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4                Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "...                 ...                                                ...  \n",
       "999995          divabat           @healingsinger thank you, i needed that   \n",
       "999996         nick1975  @vactress http://bit.ly/cADea  Maybe this is m...  \n",
       "999997            znmeb  @Brat13 Hell, Windows 7 will be out of my pric...  \n",
       "999998          virmani  @jigardoshi neah.. i wish! just reminiscing  r...  \n",
       "999999       redcomet81  @MsTeagan ...and by the way: I rewatched Sun G...  \n",
       "\n",
       "[1000000 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = Path(\"training8.csv\")\n",
    "tweets = pd.read_csv(filepath, header=None, names=[\"sentiment\", \"id\", \"time\", \"query\", \"name\", \"text\"])\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b678f168-7b7d-4b1b-9187-a5e71635fe4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NO_QUERY    1000000\n",
       "Name: query, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Does column 'NO_QUERY' contain any useful data or is every row just 'NO_QUERY'?\n",
    "tweets['query'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "710eaea7-9f6c-4699-8a7c-1c8e222428d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1          0  is upset that he can't update his Facebook by ...\n",
       "2          0  @Kenichan I dived many times for the ball. Man...\n",
       "3          0    my whole body feels itchy and like its on fire \n",
       "4          0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tweet id's and query have no data useful for sentiment analysis. There could be something in 'time,' but\n",
    "# without timezone data it can't be determined what time of day tweets were sent. Names are unlikely to be useful.\n",
    "tweets = tweets.drop(columns=['id', 'time', 'query', 'name'])\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9990ef88-e0ee-4d08-acc1-3bddb267b595",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data cleaning ideas:\n",
    "# count tokens beginning with \"@,\" store as new column \"reply_depth,\" remove tokens\"\n",
    "# count tokens beginning with \"http://,\" store as new column \"links,\" remove tokens\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4daf39a-a529-4ad3-8c18-9f730be54202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizer script\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def process_text(text): \n",
    "    sw = set(stopwords.words('english')) \n",
    "    regex = re.compile(\"[^a-zA-Z ]\") \n",
    "    re_clean = regex.sub('', text) \n",
    "    words = word_tokenize(re_clean) \n",
    "    lem = [lemmatizer.lemmatize(word) for word in words] \n",
    "    output = ' '.join([word.lower() for word in lem if word.lower() not in sw]) \n",
    "    return output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
